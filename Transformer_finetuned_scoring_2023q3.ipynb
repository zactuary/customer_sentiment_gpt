{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Purpose: The following is a program to 1) run the fine-tuned BERT transformer model to a new quarter of data and  \n",
    "#          2) do analysis on how the predicted score from the fine-tuned BERT transformer model is correlated to ChatGPT sentiment label and customer satifaction score category\n",
    "#          nps_rawgrade_category is promoters-neutrals-passives category created from customer satisfaction score, which is optional. \n",
    "#          It is included to allow for assocation analysis between model output sentiment and satisfaction store. \n",
    "#          sentiment is the sentiment label created from ChatGPT batch process, which is optional. \n",
    "#          It is included to allow for assocation analysis between model output sentiment and ChatGPT output sentiment.  \n",
    "#          This is an example program used for my Casualty Actuarial Society 2023 Annual Meeting presentation   \n",
    "# By:      Frank Zhang - Oct 2023\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "import tensorflow as tf\n",
    "from transformers import TFBertModel,  BertConfig, BertTokenizerFast\n",
    "from tensorflow.keras.layers import Input, Dropout, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.initializers import TruncatedNormal\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "from tensorflow.keras.utils import to_categorical\n",
    " \n",
    "model_name = 'bert-base-uncased'\n",
    "\n",
    "# Max length of tokens\n",
    "max_length = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Load transformers config and set output_hidden_states to False\n",
    "config = BertConfig.from_pretrained(model_name)\n",
    "config.output_hidden_states = False\n",
    "# Load BERT tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained(pretrained_model_name_or_path = model_name, config = config)\n",
    "# Load the Transformers BERT model\n",
    "transformer_bert_model = TFBertModel.from_pretrained(model_name, config = config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ------- Build the model ------- ###\n",
    "# Load the MainLayer\n",
    "bert = transformer_bert_model.layers[0]\n",
    "\n",
    "# Build your model input\n",
    "input_ids = Input(shape=(max_length,), name='input_ids', dtype='int32')\n",
    "inputs = {'input_ids': input_ids}\n",
    "\n",
    "# Load the Transformers BERT model as a layer in a Keras model\n",
    "bert_model = bert(inputs)[1]\n",
    "dropout = Dropout(config.hidden_dropout_prob, name='pooled_output')\n",
    "pooled_output = dropout(bert_model, training=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"BERT_MultiClass\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_ids (InputLayer)      [(None, 45)]              0         \n",
      "                                                                 \n",
      " bert (TFBertMainLayer)      TFBaseModelOutputWithPo   109482240 \n",
      "                             olingAndCrossAttentions             \n",
      "                             (last_hidden_state=(Non             \n",
      "                             e, 45, 768),                        \n",
      "                              pooler_output=(None, 7             \n",
      "                             68),                                \n",
      "                              past_key_values=None,              \n",
      "                             hidden_states=None, att             \n",
      "                             entions=None, cross_att             \n",
      "                             entions=None)                       \n",
      "                                                                 \n",
      " pooled_output (Dropout)     (None, 768)               0         \n",
      "                                                                 \n",
      " Sentiment (Dense)           (None, 5)                 3845      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109486085 (417.66 MB)\n",
      "Trainable params: 109486085 (417.66 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Then build your model output\n",
    "Sentiments = Dense(units=5, kernel_initializer=TruncatedNormal(stddev=config.initializer_range), name='Sentiment')(pooled_output)\n",
    "outputs = {'Sentiment': Sentiments}\n",
    "\n",
    "# And combine it all in a model object\n",
    "model_bert_multiclass = Model(inputs=inputs, outputs=outputs, name='BERT_MultiClass')\n",
    "\n",
    "# Take a look at the model\n",
    "model_bert_multiclass.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>repond_id</th>\n",
       "      <th>nps_rawgrade</th>\n",
       "      <th>comments</th>\n",
       "      <th>nps_rawgrade_category</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>topic</th>\n",
       "      <th>sentiment_gpt_clean</th>\n",
       "      <th>Sentiment_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>203950</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Great job all around.</td>\n",
       "      <td>Promoters</td>\n",
       "      <td>You have all worked hard and it shows.\\n\\nVer...</td>\n",
       "      <td>We hit our sales targets, drove more traffic ...</td>\n",
       "      <td>5:Very Postive</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>203949</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Let me know what was done with the girl that h...</td>\n",
       "      <td>Promoters</td>\n",
       "      <td>\\n\\nNeutral</td>\n",
       "      <td>\\n\\n1. Girl hitting someone\\n2. What was done ...</td>\n",
       "      <td>3:Neutral</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>203945</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Mail check directly to lender (Regions Mortgag...</td>\n",
       "      <td>Promoters</td>\n",
       "      <td>\\n\\nNeutral</td>\n",
       "      <td>\\n\\n1. Sending a check directly to lender \\n2....</td>\n",
       "      <td>3:Neutral</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>203944</td>\n",
       "      <td>10.0</td>\n",
       "      <td>No need to improve - they did a good job. Than...</td>\n",
       "      <td>Promoters</td>\n",
       "      <td>\\n\\nPositive</td>\n",
       "      <td>\\n\\n1. Appreciation \\n2. Positive feedback \\n3...</td>\n",
       "      <td>4:Postive</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>203943</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Overall we were very happy! But - I don't unde...</td>\n",
       "      <td>Promoters</td>\n",
       "      <td>\\n\\nNegative</td>\n",
       "      <td>\\n\\n1. Satisfaction with service\\n2. Payment t...</td>\n",
       "      <td>2:Negative</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  repond_id  nps_rawgrade  \\\n",
       "0           0     203950           9.0   \n",
       "1           1     203949          10.0   \n",
       "2           2     203945          10.0   \n",
       "3           3     203944          10.0   \n",
       "4           4     203943          10.0   \n",
       "\n",
       "                                            comments nps_rawgrade_category  \\\n",
       "0                              Great job all around.             Promoters   \n",
       "1  Let me know what was done with the girl that h...             Promoters   \n",
       "2  Mail check directly to lender (Regions Mortgag...             Promoters   \n",
       "3  No need to improve - they did a good job. Than...             Promoters   \n",
       "4  Overall we were very happy! But - I don't unde...             Promoters   \n",
       "\n",
       "                                           sentiment  \\\n",
       "0   You have all worked hard and it shows.\\n\\nVer...   \n",
       "1                                        \\n\\nNeutral   \n",
       "2                                        \\n\\nNeutral   \n",
       "3                                       \\n\\nPositive   \n",
       "4                                       \\n\\nNegative   \n",
       "\n",
       "                                               topic sentiment_gpt_clean  \\\n",
       "0   We hit our sales targets, drove more traffic ...      5:Very Postive   \n",
       "1  \\n\\n1. Girl hitting someone\\n2. What was done ...           3:Neutral   \n",
       "2  \\n\\n1. Sending a check directly to lender \\n2....           3:Neutral   \n",
       "3  \\n\\n1. Appreciation \\n2. Positive feedback \\n3...           4:Postive   \n",
       "4  \\n\\n1. Satisfaction with service\\n2. Payment t...          2:Negative   \n",
       "\n",
       "   Sentiment_num  \n",
       "0              4  \n",
       "1              2  \n",
       "2              2  \n",
       "3              3  \n",
       "4              1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all = pd.read_csv('./df_comment_with_gpt_sentiment_2023q3.csv')\n",
    "data_all[\"sentiment_gpt_clean\"] = np.where(data_all.sentiment.apply(lambda x: x.lower().find(\"very negative\"))>0,\"1:Very Negative\", \\\n",
    "                                                 np.where(data_all.sentiment.apply(lambda x: x.lower().find(\"negative\"))>0,\"2:Negative\", \\\n",
    "                                                          np.where(data_all.sentiment.apply(lambda x: x.lower().find(\"very positive\"))>0,\"5:Very Postive\", \\\n",
    "                                                                   np.where(data_all.sentiment.apply(lambda x: x.lower().find(\"positive\"))>0,\"4:Postive\",\"3:Neutral\"))))\n",
    "data_all['Sentiment_num']=data_all['sentiment_gpt_clean'].str[:1].astype('int')-1\n",
    "\n",
    "data_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 120s 3s/step\n"
     ]
    }
   ],
   "source": [
    "y_all = to_categorical(data_all['Sentiment_num'])# Load BERT tokenizer\n",
    "\n",
    "x_all = tokenizer(\n",
    "          text=data_all['comments'].to_list(),\n",
    "          add_special_tokens=True,\n",
    "          max_length=max_length,\n",
    "          truncation=True,\n",
    "          padding=True, \n",
    "          return_tensors='tf',\n",
    "          return_token_type_ids = False,\n",
    "          return_attention_mask = True,\n",
    "          verbose = True)\n",
    "# Restore the weights\n",
    "model_bert_multiclass.load_weights('./finedtuned_model/fine_tuned_bert_multiclass_claim_sentiment_fz')\n",
    "y_all_predicted = model_bert_multiclass.predict(\n",
    "    x={'input_ids': x_all['input_ids']},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Sentiment': array([[-1.358789  , -1.9501685 , -2.3008769 , -0.48266894,  5.777367  ],\n",
       "        [-1.1841376 , -0.09151569,  5.1973743 , -0.713212  , -1.8988496 ],\n",
       "        [-1.8998606 ,  0.23065065,  4.598942  ,  0.20221479, -1.9760107 ],\n",
       "        ...,\n",
       "        [-0.766754  ,  2.5558662 , -0.48745203,  1.7485728 , -2.9076397 ],\n",
       "        [ 1.0083941 ,  4.325148  , -1.4121637 , -1.33708   , -2.2267375 ],\n",
       "        [-0.8103707 , -1.5029817 , -2.1543064 , -0.960685  ,  5.4283257 ]],\n",
       "       dtype=float32)}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_all_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73         6\n",
      "           1       0.78      0.67      0.72       189\n",
      "           2       0.58      0.76      0.66       195\n",
      "           3       0.41      0.47      0.44       170\n",
      "           4       0.91      0.82      0.86       611\n",
      "\n",
      "    accuracy                           0.74      1171\n",
      "   macro avg       0.70      0.68      0.68      1171\n",
      "weighted avg       0.76      0.74      0.74      1171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_all_pred_max=[np.argmax(i) for i in y_all_predicted['Sentiment']]\n",
    "y_all_actual_max=[np.argmax(i) for i in y_all]\n",
    "\n",
    "\n",
    "report = classification_report(y_all_pred_max, y_all_actual_max)\n",
    "\n",
    "print(report) # 74% of accuracy b/w actual vs predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Sentiment_pred</th>\n",
       "      <th>1:Very Negative</th>\n",
       "      <th>2:Negative</th>\n",
       "      <th>3:Neutral</th>\n",
       "      <th>4:Positive</th>\n",
       "      <th>5:Very Positive</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentiment_gpt_clean</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1:Very Negative</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2:Negative</th>\n",
       "      <td>2</td>\n",
       "      <td>126</td>\n",
       "      <td>21</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3:Neutral</th>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>148</td>\n",
       "      <td>43</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4:Postive</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>80</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5:Very Postive</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>36</td>\n",
       "      <td>504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Sentiment_pred       1:Very Negative  2:Negative  3:Neutral  4:Positive  \\\n",
       "sentiment_gpt_clean                                                       \n",
       "1:Very Negative                    4           1          0           0   \n",
       "2:Negative                         2         126         21          11   \n",
       "3:Neutral                          0          48        148          43   \n",
       "4:Postive                          0           8         17          80   \n",
       "5:Very Postive                     0           6          9          36   \n",
       "\n",
       "Sentiment_pred       5:Very Positive  \n",
       "sentiment_gpt_clean                   \n",
       "1:Very Negative                    0  \n",
       "2:Negative                         1  \n",
       "3:Neutral                         15  \n",
       "4:Postive                         91  \n",
       "5:Very Postive                   504  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "lkup = {0:'1:Very Negative', 1:'2:Negative', 2:'3:Neutral',3:'4:Positive', 4:'5:Very Positive'} \n",
    "data_all[\"Sentiment_transfomer_pred\"]= [lkup[item] for item in y_all_pred_max] \n",
    " \n",
    "pd.crosstab(data_all[\"sentiment_gpt_clean\"], data_all[\"Sentiment_transfomer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross-tabulation of the predicted sentiment from fine-tuned BERT transformer model and ChatGPT sentiment class\n",
    "df_crosstab_gpt_clean_finetuned_pred = pd.crosstab(data_all[\"sentiment_gpt_clean\"], data_all[\"Sentiment_pred\"])\n",
    "# cross-tabulation of the customer satisfaction score category and ChatGPT sentiment class\n",
    "df_crosstab_nps_cat_gpt_clean = pd.crosstab(data_all[\"nps_rawgrade_category\"], data_all[\"sentiment_gpt_clean\"])\n",
    "# cross-tabulation of the customer satisfaction score category and the predicted sentiment from fine-tuned BERT transformer model \n",
    "df_crosstab_nps_cat_finetuned_pred = pd.crosstab(data_all[\"nps_rawgrade_category\"], data_all[\"Sentiment_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://www.geo.fu-berlin.de/en/v/soga-py/Basics-of-statistics/Descriptive-Statistics/Measures-of-Relation-Between-Variables/Contingency-Coeficient/index.html\n",
    "\n",
    "def contigency_coff(in_df_tab):\n",
    "    # in_df_tab : pd.crosstab\n",
    "    from scipy.stats.contingency import expected_freq\n",
    "    expected = pd.DataFrame(expected_freq(in_df_tab), columns=in_df_tab.columns, index = in_df_tab.index)\n",
    "    chisqVal = np.sum((in_df_tab.to_numpy()-expected_freq(in_df_tab))**2/expected_freq(in_df_tab))\n",
    "    C_star = np.sqrt(chisqVal/(np.sum(in_df_tab.to_numpy()) + chisqVal))\n",
    "    # Or, more concisely\n",
    "    r, c = in_df_tab.shape\n",
    "\n",
    "    k = min(r, c)\n",
    "    C_star_max = np.sqrt((k - 1) / k)\n",
    "    C = C_star / C_star_max\n",
    "    return(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.881979032732939"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contigency_coff(df_crosstab_gpt_clean_finetuned_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment_pred       1:Very Negative  2:Negative  3:Neutral  4:Positive  \\\n",
      "sentiment_gpt_clean                                                       \n",
      "1:Very Negative                    4           1          0           0   \n",
      "2:Negative                         2         126         21          11   \n",
      "3:Neutral                          0          48        148          43   \n",
      "4:Postive                          0           8         17          80   \n",
      "5:Very Postive                     0           6          9          36   \n",
      "\n",
      "Sentiment_pred       5:Very Positive  \n",
      "sentiment_gpt_clean                   \n",
      "1:Very Negative                    0  \n",
      "2:Negative                         1  \n",
      "3:Neutral                         15  \n",
      "4:Postive                         91  \n",
      "5:Very Postive                   504  \n",
      "0.881979032732939\n"
     ]
    }
   ],
   "source": [
    "print(df_crosstab_gpt_clean_finetuned_pred)\n",
    "print(contigency_coff(df_crosstab_gpt_clean_finetuned_pred)) \n",
    "# 88% contingency coeff on new quarter of data between the predicted sentiment from fine-tuned BERT transformer model and ChatGPT sentiment class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6080631833192912"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contigency_coff(df_crosstab_nps_cat_gpt_clean) # contingency score of 60.8% b/w customer satisfaction score category and ChatGPT sentiment class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6003578894873848"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contigency_coff(df_crosstab_nps_cat_finetuned_pred) # # contingency score of 60.0% b/w customer satisfaction score category and the predicted sentiment from fine-tuned BERT transformer model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all.to_excel(\"./df_comment_out_gpt_finetunemod_score_2023q3.xlsx\", index=False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
